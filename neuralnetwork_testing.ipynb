{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d (1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d (6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120)\n",
      "  (fc2): Linear(in_features=120, out_features=84)\n",
      "  (fc3): Linear(in_features=84, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# lets code a simple feed forward neural network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # 6 input channels, 16 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # we also need some linear transformations; these are initialised by their in_ and out_features\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 16 output ch from second layer times the kernel size \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  \n",
    "        # I don't know, where 120, 84 and 10 come from; but they stem from the picture in the tutorial\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        # => from a 2x2 window take the max value. relu = Rectified Linear unit; relu(x) = max(0,x)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we created a ```forward``` function, a ```backward``` function will be created automagically. The backward function can then be used for \n",
    "``` autograd ```. \n",
    "\n",
    "learnable parameters of a model: ```net.parameters()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.0243  0.0660 -0.1330 -0.1541 -0.1973\n",
      "  0.0709  0.0343  0.1709  0.1624 -0.0348\n",
      " -0.1038  0.1492  0.0972 -0.0673  0.0110\n",
      "  0.0843 -0.1877  0.0932 -0.1139 -0.0879\n",
      "  0.0791 -0.0629 -0.1274  0.1480 -0.1263\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  0.1253 -0.1703 -0.1055 -0.0463 -0.0287\n",
      " -0.1286  0.1820 -0.1123  0.1013  0.1505\n",
      "  0.0251  0.1256  0.0632  0.1710  0.0744\n",
      " -0.1606  0.1198  0.0847  0.1633  0.0825\n",
      "  0.1223  0.0258 -0.1176  0.0064 -0.1164\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.0666  0.0922 -0.0761  0.1710  0.1152\n",
      "  0.1615  0.0906  0.1579 -0.1165 -0.0946\n",
      "  0.1658  0.0144 -0.1873 -0.1908 -0.1246\n",
      "  0.0061 -0.1969 -0.1835 -0.0562 -0.0316\n",
      "  0.1807 -0.1750 -0.1308  0.1415 -0.0436\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      " -0.0488  0.0050  0.0904  0.1844 -0.0693\n",
      "  0.1241  0.1377  0.0198  0.1808  0.0406\n",
      " -0.1071  0.0817 -0.1523 -0.1795  0.0721\n",
      " -0.0534  0.0055 -0.0136  0.1909 -0.0336\n",
      " -0.1597 -0.1837  0.1358  0.1471 -0.1792\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      "  0.0265 -0.1899 -0.1786  0.0210 -0.1534\n",
      "  0.1675  0.1504 -0.0888 -0.0445  0.1294\n",
      " -0.0872 -0.0285 -0.0605 -0.0698 -0.1217\n",
      " -0.0414 -0.1498 -0.0417 -0.1322  0.0205\n",
      "  0.1199  0.0316 -0.1568  0.1125 -0.0112\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      "  0.1794 -0.1148  0.0394 -0.1679 -0.1188\n",
      "  0.0384  0.0656  0.1253  0.1042  0.1698\n",
      " -0.1168  0.1045 -0.1336  0.0167 -0.1136\n",
      " -0.0415 -0.1095 -0.1667  0.1875  0.0683\n",
      " -0.0083 -0.1148  0.1672 -0.1291 -0.1864\n",
      "[torch.FloatTensor of size 6x1x5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params[0])\n",
    "# NOTE: I don't know exactly what these weights correspond to in the actual network above. \n",
    "# In the sense of: how does the network look like, where do these weights actually sit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the ```forward``` method is an ```autograd.Variable```. The produced output is of the same type. \n",
    "The CNN expects an input of $32 \\times 32$ picture sizes. how does that work? let's walk through that:\n",
    "\n",
    "First, let us just assume for the moment, that we have a $32\\times32\\times1$ sized picture (we only have one colour channel, hence BW picture). Our first layer ```net.conv1``` has a $5\\times5$ convolutional layer, with kernel size (KS) of $5$ and $6$ outputs $\\Leftarrow 6$ kernels.\n",
    "\n",
    "The default values in ```torch.nn.Conv2d``` for ```stride``` and ```padding``` are $1$ and $0$ respectively. Since we didn't set any padding ourselves, we'll lose some information of the image. If the function\n",
    "```python\n",
    "out = lambda wid,KS,pad,st: ((wid-KS+2*pad)/st+1)\n",
    "```\n",
    "with wid=width, KS=kernel size, pad=padding, st=stride, returns an integer, we don't lose information. In our case we have ```out(32, 5, 0, 1)=13.5```.\n",
    "\n",
    "The loss of information is $\\mathsf{KS} -1$, so after ```net.conv1``` we end up with $28\\times28\\times6$, because we have 6 outputs. This is fed into the 2d pooling layer of $2\\times2$, so we get $14\\times14\\times6$, because channels aren't pooled.\n",
    "Same procedure again with layer ```net.conv2``` $\\Rightarrow\\ 10\\times10\\times16$, and after pooling $5\\times5\\times16$.\n",
    "\n",
    "This output tensor is then streched into a 1d object, such that ```net.fc1``` is able to use it. Hence the $16\\cdot 5 \\cdot 5$ input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0035  0.1019 -0.0021 -0.0666  0.0568  0.0193 -0.0635 -0.1036 -0.0144 -0.0583\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32))  # variable takes a 4-dim tensor: nSamples x nChannels x Height x Width\n",
    "# what is a channel? think of an RGB picture - it has 3 channels, each for a certain colour. each channel has info\n",
    "# about the whole picture\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 µs ± 1.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function to get an idea, how long it takes for a network to do a full data propagation with weight adaption\n",
    "# still to add: weight adaption with learning rate, loss function, ..\n",
    "def test(net):\n",
    "    input = Variable(torch.randn(1,1,32,32))\n",
    "    out = net(input)\n",
    "    net.zero_grad()\n",
    "    out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0040  0.1117 -0.0444 -0.0671  0.0633 -0.0058 -0.0577 -0.1043 -0.0062 -0.0718\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = lambda w,k,p,s: ((w-k+2*p)/s+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
